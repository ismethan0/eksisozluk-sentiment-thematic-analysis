# NLP Model SeÃ§imi - GÃ¼ncellenmiÅŸ YaklaÅŸÄ±m

## ğŸ¯ KullanÄ±lan Modeller

### Duygu Analizi
**Model:** `incidelen/xlm-roberta-base-turkish-sentiment-analysis`
- âœ… **Ã–nceden eÄŸitilmiÅŸ** - Ekstra eÄŸitim gerektirmez
- âœ… XLM-RoBERTa tabanlÄ± (Ã§ok dilli, TÃ¼rkÃ§e'de gÃ¼Ã§lÃ¼)
- âœ… TÃ¼rkÃ§e sentiment iÃ§in optimize edilmiÅŸ
- âœ… HuggingFace pipeline ile kolay kullanÄ±m
- âš¡ GPU desteÄŸi (varsa otomatik kullanÄ±r)

**Ã‡Ä±ktÄ± FormatÄ±:**
```json
{
  "label": "POSITIVE" | "NEUTRAL" | "NEGATIVE",
  "score": 0.95
}
```

### Tema Analizi
**Model:** `BERTopic + emrecan/bert-base-turkish-cased-mean-nli-stsb-tr`
- âœ… BERTopic - Unsupervised topic modeling
- âœ… TÃ¼rkÃ§e SentenceTransformer embeddings
- âœ… Otomatik tema keÅŸfi
- âœ… Topic labeling ve visualization

---

## ğŸ“¦ Kurulum

### 1. Gerekli Paketler
```powershell
pip install torch transformers sentencepiece
pip install bertopic sentence-transformers
pip install umap-learn hdbscan
```

### 2. Model Ä°ndirme

**Otomatik (Ä°lk KullanÄ±mda):**
Modeller ilk Ã§alÄ±ÅŸtÄ±rmada HuggingFace Hub'dan otomatik indirilir.

**Manuel (Google Colab'da):**
```python
# Colab'da eÄŸit/test, sonra Drive'a kaydet
sentiment_model.save_pretrained('/content/drive/MyDrive/eksisozluk_sentiment_model')
topic_model.save('/content/drive/MyDrive/eksisozluk_topic_model')
```

---

## ğŸš€ KullanÄ±m

### Google Colab

1. `colab_training.py` iÃ§eriÄŸini kopyala
2. Colab'da yeni notebook oluÅŸtur
3. GPU runtime seÃ§in (T4 veya A100)
4. HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±r:

```python
# CELL 1: GPU + Drive
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
from google.colab import drive
drive.mount('/content/drive')

# CELL 2: Paket kurulumu
!pip install transformers bertopic sentence-transformers

# CELL 3: Veri yÃ¼kleme
DATA_PATH = '/content/drive/MyDrive/eksisozluk_dataset.json'
# ... (veri yÃ¼kleme kodu)

# CELL 4: Duygu modeli (Ã¶nceden eÄŸitilmiÅŸ)
from transformers import pipeline
sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="incidelen/xlm-roberta-base-turkish-sentiment-analysis",
    device=0
)

# CELL 5: Tema modeli eÄŸitimi
from bertopic import BERTopic
topic_model = BERTopic(language="turkish")
topics, probs = topic_model.fit_transform(docs)

# CELL 6: Test
result = sentiment_pipeline("Bu Ã§ok gÃ¼zel bir Ã¼rÃ¼n!")
print(result)  # [{'label': 'POSITIVE', 'score': 0.99}]

# CELL 7: Kaydet
sentiment_pipeline.save_pretrained('/content/drive/MyDrive/models/sentiment')
topic_model.save('/content/drive/MyDrive/models/topic')
```

### Local Flask App

```python
# services/trained_nlp_service.py otomatik yÃ¼kler
from services.trained_nlp_service import get_nlp_service

nlp = get_nlp_service()

# Tek metin analizi
result = nlp.analyze_sentiment("Harika bir Ã¼rÃ¼n!")
# {'label': 'POSITIVE', 'score': 0.98}

# Batch analizi
results = nlp.analyze_sentiment_batch(["GÃ¼zel", "KÃ¶tÃ¼", "Normal"])

# Tema analizi
topics = nlp.analyze_topics(["Python programlama", "Makine Ã¶ÄŸrenmesi"])
```

---

## ğŸ”„ Ä°ÅŸ AkÄ±ÅŸÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. LOCAL: Veri     â”‚
â”‚  collect_data.py    â”‚
â”‚  â†’ JSON output      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. DRIVE: Upload   â”‚
â”‚  JSON â†’ Drive       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. COLAB: EÄŸitim   â”‚
â”‚  â€¢ Sentiment: Zaten â”‚
â”‚    eÄŸitilmiÅŸ âœ“      â”‚
â”‚  â€¢ Topic: EÄŸit      â”‚
â”‚    (5-10 dk)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. DRIVE: Kaydet   â”‚
â”‚  Models â†’ Drive     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. LOCAL: Ä°ndir    â”‚
â”‚  Drive â†’ models/    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. LOCAL: Kullan   â”‚
â”‚  Flask app.py       â”‚
â”‚  â†’ API endpoints    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Performans

### Duygu Analizi
| Metric | Value |
|--------|-------|
| Model Size | ~550 MB |
| Inference Time | ~50ms/text (GPU) |
| Accuracy | ~89% (TÃ¼rkÃ§e benchmark) |
| Labels | 3 (POSITIVE, NEUTRAL, NEGATIVE) |

### Tema Analizi
| Metric | Value |
|--------|-------|
| Model Size | ~420 MB (embeddings) |
| Training Time | 5-10 dk (1500 docs) |
| Topics Found | Auto (typically 10-30) |
| Visualization | âœ… HTML exports |

---

## ğŸ“ Avantajlar

### Ã–nceki YaklaÅŸÄ±m (BERTurk EÄŸitimi)
- âŒ Manuel etiketleme gerekli (1000+ entry)
- âŒ EÄŸitim zamanÄ±: 20-30 dakika
- âŒ Overfitting riski
- âŒ Veri kalitesi kritik

### Yeni YaklaÅŸÄ±m (XLM-RoBERTa Pre-trained)
- âœ… **SÄ±fÄ±r etiketleme** - Hemen kullan
- âœ… EÄŸitim zamanÄ±: 0 dakika (zaten eÄŸitilmiÅŸ)
- âœ… GeniÅŸ veri seti ile eÄŸitilmiÅŸ (robust)
- âœ… Production-ready

---

## ğŸ” API Ã–rnekleri

### Sentiment Endpoint
```bash
POST /api/analyze/sentiment
{
  "text": "Bu film gerÃ§ekten Ã§ok gÃ¼zeldi!"
}

# Response
{
  "success": true,
  "data": {
    "sentiment": "POSITIVE",
    "score": 0.9876,
    "model": "trained"
  }
}
```

### Batch Endpoint
```bash
POST /api/analyze/batch
{
  "entries": [
    {"id": 1, "text": "MÃ¼kemmel Ã¼rÃ¼n"},
    {"id": 2, "text": "Berbat deneyim"}
  ]
}

# Response
{
  "success": true,
  "data": {
    "summary": {
      "sentiment_distribution": {
        "POSITIVE": 1,
        "NEGATIVE": 1
      }
    },
    "entries": [...]
  }
}
```

---

## ğŸ› ï¸ Troubleshooting

### Problem: "Model not found"
```powershell
# Ä°lk Ã§alÄ±ÅŸtÄ±rmada otomatik indirilir
# Manuel indirme:
python -c "from transformers import pipeline; pipeline('sentiment-analysis', model='incidelen/xlm-roberta-base-turkish-sentiment-analysis')"
```

### Problem: CUDA Out of Memory
```python
# CPU kullan
sentiment_pipeline = pipeline(..., device=-1)
```

### Problem: Slow inference
```python
# Batch kullan (Ã§ok daha hÄ±zlÄ±)
results = nlp.analyze_sentiment_batch(texts)  # vs tek tek
```

---

## ğŸ“š Kaynaklar

- [XLM-RoBERTa Model](https://huggingface.co/incidelen/xlm-roberta-base-turkish-sentiment-analysis)
- [BERTopic Docs](https://maartengr.github.io/BERTopic/)
- [Turkish SentenceTransformer](https://huggingface.co/emrecan/bert-base-turkish-cased-mean-nli-stsb-tr)
- [Transformers Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)
