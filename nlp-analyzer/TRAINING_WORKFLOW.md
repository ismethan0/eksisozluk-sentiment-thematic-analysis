# EkÅŸi SÃ¶zlÃ¼k NLP - Model EÄŸitimi Ä°ÅŸ AkÄ±ÅŸÄ±

Google Colab'dan localhost API'ye eriÅŸilemediÄŸi iÃ§in veri toplama ve model eÄŸitimi ayrÄ± yapÄ±lÄ±yor.

## ğŸ“‹ Ä°ÅŸ AkÄ±ÅŸÄ± Ã–zeti

```
1. LOCAL: Veri Toplama (collect_data.py)
   â†“
2. DRIVE: JSON DosyasÄ±nÄ± YÃ¼kle
   â†“
3. COLAB: Model EÄŸitimi (colab_training.py)
   â†“
4. DRIVE: EÄŸitilmiÅŸ Modelleri Kaydet
   â†“
5. LOCAL: Modelleri Ä°ndir ve Kullan
```

---

## ğŸ”§ AdÄ±m 1: Localde Veri Toplama

### 1.1 Node.js API'yi BaÅŸlat

```powershell
cd c:\Users\ismet\Desktop\Ders\4.sÄ±nÄ±f\Dogal_dil\eksisozluk-api-master
npm start
```

API `http://localhost:3000` adresinde Ã§alÄ±ÅŸacak.

### 1.2 Veri Toplama Script'ini Ã‡alÄ±ÅŸtÄ±r

```powershell
cd c:\Users\ismet\Desktop\Ders\4.sÄ±nÄ±f\Dogal_dil\nlp-analyzer
python collect_data.py
```

Bu script:
- âœ… 15 farklÄ± baÅŸlÄ±ktan veri toplar
- âœ… Her baÅŸlÄ±k iÃ§in 10 sayfa (yaklaÅŸÄ±k 100 entry)
- âœ… Toplam ~1500 entry beklenebilir
- âœ… JSON formatÄ±nda kaydeder: `eksisozluk_dataset_YYYYMMDD_HHMMSS.json`

**Toplanan Veri FormatÄ±:**
```json
{
  "metadata": {
    "total_entries": 1523,
    "topics": ["teknoloji", "politika", ...],
    "collected_at": "2025-01-29T12:00:00"
  },
  "entries": [
    {
      "id": "123456",
      "author": "yazar_nick",
      "body": "entry metni...",
      "date": "12.01.2025",
      "fav_count": 5,
      "topic": "teknoloji",
      "page": 1
    }
  ]
}
```

### 1.3 Ã–zelleÅŸtirme (Opsiyonel)

`collect_data.py` dosyasÄ±nÄ± dÃ¼zenleyerek:
- Daha fazla baÅŸlÄ±k ekleyin
- Sayfa sayÄ±sÄ±nÄ± artÄ±rÄ±n (max_pages=20)
- Rate limiting ayarlayÄ±n (time.sleep)

---

## ğŸ“¤ AdÄ±m 2: Google Drive'a YÃ¼kleme

1. OluÅŸan JSON dosyasÄ±nÄ± bulun: `eksisozluk_dataset_*.json`
2. Google Drive'Ä±nÄ±zda bir klasÃ¶r oluÅŸturun: `Eksi_NLP_Project`
3. JSON dosyasÄ±nÄ± bu klasÃ¶re yÃ¼kleyin

**Dizin YapÄ±sÄ±:**
```
Google Drive/
â””â”€â”€ Eksi_NLP_Project/
    â”œâ”€â”€ eksisozluk_dataset_20250129_120000.json
    â””â”€â”€ (eÄŸitilmiÅŸ modeller buraya kaydedilecek)
```

---

## ğŸ“ AdÄ±m 3: Google Colab'da Model EÄŸitimi

### 3.1 Colab Notebook OluÅŸtur

1. [Google Colab](https://colab.research.google.com/) aÃ§Ä±n
2. **Runtime â†’ Change runtime type â†’ GPU (T4)** seÃ§in
3. Yeni notebook oluÅŸturun

### 3.2 `colab_training.py` Ä°Ã§eriÄŸini Kopyala

Bu repodaki `colab_training.py` dosyasÄ±nÄ± aÃ§Ä±n ve iÃ§eriÄŸi Colab'a yapÄ±ÅŸtÄ±rÄ±n.

**Ã–NEMLÄ°:** 
```python
# CELL 3'te bu satÄ±rÄ± gÃ¼ncelleyin:
DATA_PATH = '/content/drive/MyDrive/Eksi_NLP_Project/eksisozluk_dataset_20250129_120000.json'
```

### 3.3 HÃ¼creleri SÄ±rayla Ã‡alÄ±ÅŸtÄ±r

| HÃ¼cre | AÃ§Ä±klama | SÃ¼re |
|-------|----------|------|
| CELL 1 | GPU kontrolÃ¼ ve Drive mount | ~30 sn |
| CELL 2 | Paket kurulumu | ~2-3 dk |
| CELL 3 | Veri yÃ¼kleme ve temizleme | ~10 sn |
| CELL 4 | Duygu analizi modeli eÄŸitimi | ~10-20 dk |
| CELL 5 | Tema analizi (BERTopic) | ~5-10 dk |
| CELL 6 | Model testleri | ~30 sn |
| CELL 7 | SonuÃ§larÄ± kaydetme | ~1 dk |

**Toplam SÃ¼re:** ~20-35 dakika (T4 GPU ile)

### 3.4 EÄŸitim SonrasÄ± Drive KontrolÃ¼

Drive'da ÅŸunlar oluÅŸacak:
```
Eksi_NLP_Project/
â”œâ”€â”€ eksisozluk_dataset_20250129_120000.json
â”œâ”€â”€ eksisozluk_sentiment_model/  â† Duygu analizi
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ tokenizer_config.json
â”œâ”€â”€ eksisozluk_topic_model/      â† Tema analizi
â”‚   â””â”€â”€ ... (BERTopic dosyalarÄ±)
â”œâ”€â”€ model_training_results.json
â”œâ”€â”€ topic_visualization.html
â””â”€â”€ topic_barchart.html
```

---

## ğŸ’¾ AdÄ±m 4: Modelleri Ä°ndirme

### 4.1 Drive'dan Ä°ndir

Google Drive'dan ÅŸu klasÃ¶rleri indirin:
- `eksisozluk_sentiment_model/`
- `eksisozluk_topic_model/`

### 4.2 Local Projeye YerleÅŸtir

```powershell
cd c:\Users\ismet\Desktop\Ders\4.sÄ±nÄ±f\Dogal_dil\nlp-analyzer

# models klasÃ¶rÃ¼ oluÅŸtur
mkdir models

# Ä°ndirilen modelleri kopyala
# Windows Explorer'dan models/ klasÃ¶rÃ¼ne yapÄ±ÅŸtÄ±rÄ±n
```

**Son dizin yapÄ±sÄ±:**
```
nlp-analyzer/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ eksisozluk_sentiment_model/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”‚   â””â”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ eksisozluk_topic_model/
â”‚       â””â”€â”€ (BERTopic dosyalarÄ±)
â”œâ”€â”€ services/
â”‚   â””â”€â”€ trained_nlp_service.py
â””â”€â”€ app.py
```

---

## ğŸš€ AdÄ±m 5: Local'de Modeli Kullanma

### 5.1 Gerekli Paketleri YÃ¼kle

```powershell
cd c:\Users\ismet\Desktop\Ders\4.sÄ±nÄ±f\Dogal_dil\nlp-analyzer

# EÄŸer daha Ã¶nce yÃ¼klemediyseniz:
pip install torch transformers bertopic sentence-transformers
```

### 5.2 Flask UygulamasÄ±nÄ± BaÅŸlat

```powershell
python app.py
```

BaÅŸlangÄ±Ã§ta ÅŸu mesajlarÄ± gÃ¶rmelisiniz:
```
Loading sentiment model from models/eksisozluk_sentiment_model
âœ“ Sentiment model loaded
Loading topic model from models/eksisozluk_topic_model
âœ“ Topic model loaded
âœ“ Trained NLP models loaded successfully
 * Running on http://localhost:5000
```

### 5.3 Test Et

Frontend'den "TÃ¼mÃ¼nÃ¼ Analiz Et" butonuna basÄ±n. ArtÄ±k:
- âœ… EÄŸitilmiÅŸ BERTurk modeli duygu analizi yapÄ±yor
- âœ… BERTopic gerÃ§ek tema keÅŸfi yapÄ±yor
- âœ… Batch iÅŸleme Ã§ok daha hÄ±zlÄ±

---

## ğŸ” SonuÃ§larÄ± Kontrol Etme

### API Response Format

**EÄŸitilmiÅŸ model kullanÄ±ldÄ±ÄŸÄ±nda:**
```json
{
  "success": true,
  "data": {
    "sentiment": "Positive",
    "score": 0.95,
    "all_scores": {
      "Negative": 0.02,
      "Neutral": 0.03,
      "Positive": 0.95
    },
    "model": "trained"  â† EÄŸitilmiÅŸ model kullanÄ±lÄ±yor
  }
}
```

**Fallback (model yoksa):**
```json
{
  "data": {
    "sentiment": "positive",
    "model": "basic"  â† Basit sÃ¶zlÃ¼k tabanlÄ±
  }
}
```

---

## âš ï¸ Sorun Giderme

### Problem 1: "Import torch could not be resolved"

```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Problem 2: "Sentiment model not found"

`app.py` Ã§Ä±ktÄ±sÄ±nÄ± kontrol edin:
```
âš  Sentiment model not found at models/eksisozluk_sentiment_model
  Using basic NLP service as fallback
```

**Ã‡Ã¶zÃ¼m:** Model dosyalarÄ±nÄ± doÄŸru yere kopyalayÄ±n.

### Problem 3: EÄŸitim Ã§ok uzun sÃ¼rÃ¼yor

Colab'da:
- **Runtime â†’ Change runtime type â†’ GPU** seÃ§ili mi?
- `training_args` iÃ§inde `per_device_train_batch_size=8` yapÄ±n (daha hÄ±zlÄ± ama daha az doÄŸru)
- `num_train_epochs=2` yapÄ±n

### Problem 4: Out of Memory (OOM)

```python
# CELL 4'te batch size'Ä± dÃ¼ÅŸÃ¼rÃ¼n:
per_device_train_batch_size=8  # 16 yerine
```

---

## ğŸ“Š Veri Etiketleme (GeliÅŸmiÅŸ)

Otomatik etiketleme yerine **manuel etiketleme** daha iyi sonuÃ§ verir.

### Basit Etiketleme Tool'u

```python
# label_data.py
import json

with open('eksisozluk_dataset.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

labeled = []
for entry in data['entries'][:100]:  # Ä°lk 100 entry
    print(f"\n{entry['body']}")
    print("0=Negative, 1=Neutral, 2=Positive, s=Skip:")
    
    label = input()
    if label in ['0', '1', '2']:
        labeled.append({
            **entry,
            'sentiment_label': int(label)
        })

# Kaydet
with open('labeled_dataset.json', 'w', encoding='utf-8') as f:
    json.dump(labeled, f, ensure_ascii=False, indent=2)
```

---

## ğŸ¯ Sonraki AdÄ±mlar

1. **Daha Fazla Veri:**
   - 5000-10000 entry toplayÄ±n
   - Ã‡eÅŸitli baÅŸlÄ±klardan dengeli veri

2. **Manuel Etiketleme:**
   - 500-1000 entry'yi manuel etiketleyin
   - Daha doÄŸru model eÄŸitimi

3. **Fine-tuning:**
   - Etiketli veri ile modeli tekrar eÄŸitin
   - EkÅŸi SÃ¶zlÃ¼k diline Ã¶zelleÅŸmiÅŸ model

4. **Model KarÅŸÄ±laÅŸtÄ±rma:**
   - Basit vs EÄŸitilmiÅŸ model performansÄ±
   - Confusion matrix ile analiz

5. **Deployment:**
   - Modeli kÃ¼Ã§Ã¼ltme (quantization)
   - API caching
   - Database entegrasyonu

---

## ğŸ“š Kaynaklar

- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [BERTopic Guide](https://maartengr.github.io/BERTopic/)
- [BERTurk Model](https://huggingface.co/dbmdz/bert-base-turkish-cased)
- [Google Colab Tips](https://colab.research.google.com/notebooks/welcome.ipynb)
