"""
TestVeri_Duygulu.xlsx dosyasÄ±ndaki entry'leri okuyup 
duygu analizini yapÄ±p Twitter sÃ¼tununa yazan script
"""

import os
import sys
import unicodedata
import pandas as pd
from dotenv import load_dotenv

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# NLP servisini import et
from services.nlp_service import NLPService

def analyze_test_data(input_file='TestVeri_Duygulu.xlsx', output_file='TestVeri_Duygulu_Analyzed.xlsx', samples_per_category=10):
    """
    Excel dosyasÄ±ndaki entry'leri okuyup duygu ve tema analizi yap
    Her kategoriden dengeli sayÄ±da Ã¶rnek seÃ§er
    
    SÃ¼tunlar:
        body: Analiz edilecek metin
        RDuygu: GerÃ§ek duygu etiketi
        Rkategori: GerÃ§ek kategori
        Tduygu: Model tahmini (0=negative, 1=neutral, 2=positive)
        Tkategori: Model kategori tahmini
        topic: GerÃ§ek kategori adÄ± (Rkategori'den kopyalanÄ±r)
    
    Args:
        input_file: Okunacak Excel dosyasÄ±
        output_file: SonuÃ§larÄ±n yazÄ±lacaÄŸÄ± Excel dosyasÄ±
        samples_per_category: Her kategoriden kaÃ§ Ã¶rnek alÄ±nacak (varsayÄ±lan: 10)
    """
    print(f"ðŸ“– Reading file: {input_file}")
    
    try:
        # Excel dosyasÄ±nÄ± oku
        df = pd.read_excel(input_file)
        print(f"   Found {len(df)} rows")
        
        # SÃ¼tun isimlerini kontrol et
        print(f"   Columns: {list(df.columns)}")
        
        # Gerekli sÃ¼tunlarÄ± kontrol et
        required_cols = ['body', 'RDuygu', 'Rkategori']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            print(f"âŒ Gerekli sÃ¼tunlar bulunamadÄ±: {missing_cols}")
            print(f"   Mevcut sÃ¼tunlar: {list(df.columns)}")
            return
        
        # BoÅŸ deÄŸerleri filtrele
        df_clean = df[(df['body'].notna()) & (df['body'] != '') & 
                      (df['RDuygu'].notna()) & (df['RDuygu'] != '') &
                      (df['Rkategori'].notna()) & (df['Rkategori'] != '')].copy()
        
        print(f"   Valid rows after filtering: {len(df_clean)}")
        
        # Her kategoriden dengeli Ã¶rnekleme yap
        print(f"\nðŸ“Š Sampling {samples_per_category} entries per category...")
        
        # Kategori daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶ster
        category_counts = df_clean['Rkategori'].value_counts()
        print(f"   Available categories:")
        for cat, count in category_counts.items():
            print(f"      {cat}: {count} entries")
        
        # Her kategoriden Ã¶rnek seÃ§
        sampled_dfs = []
        for category in category_counts.index:
            cat_df = df_clean[df_clean['Rkategori'] == category]
            sample_size = min(samples_per_category, len(cat_df))
            sampled = cat_df.sample(n=sample_size, random_state=42)
            sampled_dfs.append(sampled)
            print(f"      Selected {sample_size} from {category}")
        
        # Ã–rnekleri birleÅŸtir ve karÄ±ÅŸtÄ±r
        df_sampled = pd.concat(sampled_dfs, ignore_index=True)
        df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)
        
        print(f"\n   Total samples selected: {len(df_sampled)}")
        
        # Yeni sÃ¼tunlar ekle
        df_sampled['Tduygu'] = ''
        df_sampled['Tkategori'] = ''
        df_sampled['topic'] = df_sampled['Rkategori']  # topic = Rkategori
        
        print(f"   Columns: body, RDuygu, Rkategori, topic")
        print(f"   Will predict: Tduygu, Tkategori")
        
        # NLP servisini baÅŸlat
        print("\nðŸ¤– Initializing NLP service...")
        nlp_service = NLPService()
        
        # Her entry iÃ§in duygu ve tema analizi yap
        print(f"\nðŸ”¬ Analyzing {len(df_sampled)} entries...")
        
        sentiment_results = []
        category_results = []
        
        for idx, row in df_sampled.iterrows():
            body_text = str(row['body'])
            
            try:
                # Hem duygu hem tema analizi yap
                combined_result = nlp_service.analyze_combined(body_text)
                
                # Duygu analizi sonucu -> 0, 1, 2 formatÄ±nda
                sentiment = combined_result['sentiment']['sentiment']
                sentiment_map = {
                    'negative': 0,
                    'neutral': 1,
                    'positive': 2
                }
                sentiment_code = sentiment_map.get(sentiment, 1)
                
                # Tema analizi sonucu
                main_topic = combined_result['theme']['main_topic']
                
                sentiment_results.append(sentiment_code)
                category_results.append(main_topic)
                
                # Ä°lerleme gÃ¶ster (her 5 kayÄ±tta bir)
                if (len(sentiment_results)) % 5 == 0:
                    print(f"   Progress: {len(sentiment_results)}/{len(df_sampled)}")
                
            except Exception as e:
                print(f"   [Row {idx}] Error: {e}")
                sentiment_results.append('')
                category_results.append('')
        
        # SonuÃ§larÄ± sÃ¼tunlara yaz
        df_sampled['Tduygu'] = sentiment_results
        df_sampled['Tkategori'] = category_results
        
        print(f"\n   âœ… Analysis completed: {len(sentiment_results)} entries processed")
        
        # SonuÃ§larÄ± kaydet
        print(f"\nðŸ’¾ Saving results to: {output_file}")
        df_sampled.to_excel(output_file, index=False)
        
        # Ã–zet istatistikler
        total_samples = len(df_sampled)
        print("\nðŸ“Š Summary:")
        
        print("\n   Topic (Rkategori) Distribution:")
        topic_counts = df_sampled['topic'].value_counts()
        for topic, count in topic_counts.items():
            percentage = (count / total_samples) * 100
            print(f"      {topic}: {count} ({percentage:.1f}%)")
        
        print("\n   Tduygu Distribution:")
        sentiment_counts = df_sampled['Tduygu'].value_counts()
        sentiment_labels = {0: 'negative', 1: 'neutral', 2: 'positive'}
        for code, count in sentiment_counts.items():
            if code != '':
                percentage = (count / total_samples) * 100
                label = sentiment_labels.get(code, 'unknown')
                print(f"      {code} ({label}): {count} ({percentage:.1f}%)")
        
        print("\n   Tkategori Distribution:")
        category_counts = df_sampled['Tkategori'].value_counts()
        for category, count in category_counts.items():
            if category != '':
                percentage = (count / total_samples) * 100
                print(f"      {category}: {count} ({percentage:.1f}%)")
        
        # DoÄŸruluk hesaplama
        print(f"\nðŸŽ¯ Accuracy Metrics:")
        
        # RDuygu'yu 0,1,2 formatÄ±na Ã§evir
        rduygu_map = {
            'negative': 0, 'neg': 0, 'olumsuz': 0, '-1': 0, -1: 0, 0: 0, '0': 0,
            'neutral': 1, 'neu': 1, 'nÃ¶tr': 1, 'notr': 1, '0': 1, 0: 1, 1: 1, '1': 1,
            'positive': 2, 'pos': 2, 'olumlu': 2, '1': 2, 1: 2, 2: 2, '2': 2
        }
        
        # GeÃ§erli satÄ±rlarÄ± filtrele
        valid_mask = (df_sampled['Tduygu'] != '') & (df_sampled['RDuygu'] != '')
        valid_df = df_sampled[valid_mask].copy()
        
        if len(valid_df) > 0:
            # RDuygu'yu normalize et
            valid_df['RDuygu_normalized'] = valid_df['RDuygu'].apply(
                lambda x: rduygu_map.get(str(x).lower().strip(), rduygu_map.get(x, -1))
            )
            
            # Sadece baÅŸarÄ±yla eÅŸleÅŸenleri al
            valid_df = valid_df[valid_df['RDuygu_normalized'].isin([0, 1, 2])]
            
            if len(valid_df) > 0:
                true_labels = valid_df['RDuygu_normalized']
                pred_labels = valid_df['Tduygu']
                
                print("\n   === SENTIMENT ACCURACY ===")
                
                # Accuracy hesapla
                correct = (true_labels == pred_labels).sum()
                total = len(valid_df)
                accuracy = correct / total
                
                print(f"   Total valid samples: {total}")
                print(f"   Correct predictions: {correct}")
                print(f"   Accuracy: {accuracy:.2%}")
                
                # Sklearn varsa detaylÄ± metrikler
                try:
                    from sklearn.metrics import classification_report, confusion_matrix
                    
                    print("\nðŸ“ˆ Classification Report:")
                    target_names = ['negative (0)', 'neutral (1)', 'positive (2)']
                    print(classification_report(true_labels, pred_labels, target_names=target_names, zero_division=0))
                    
                    print("\nðŸ”¢ Confusion Matrix:")
                    cm = confusion_matrix(true_labels, pred_labels, labels=[0, 1, 2])
                    
                    # Confusion matrix'i gÃ¼zel formatta yazdÄ±r
                    print(f"{'':15} {'Pred-0':>10} {'Pred-1':>10} {'Pred-2':>10}")
                    labels_text = ['True-0 (neg)', 'True-1 (neu)', 'True-2 (pos)']
                    for i, label in enumerate(labels_text):
                        print(f"{label:15}", end='')
                        for j in range(3):
                            print(f"{cm[i][j]:>10}", end='')
                        print()
                    
                except ImportError:
                    print("\n   ðŸ’¡ Tip: Install scikit-learn for detailed metrics:")
                    print("      pip install scikit-learn")
                
                # Kategori doÄŸruluÄŸu (Rkategori vs Tkategori)
                print("\n   === CATEGORY ACCURACY ===")
                valid_cat_mask = (df_sampled['Tkategori'] != '') & (df_sampled['Rkategori'] != '')
                valid_cat_df = df_sampled[valid_cat_mask].copy()
                
                if len(valid_cat_df) > 0:
                    def _normalize(label: object) -> str:
                        text = str(label).strip().lower().replace('â€™', "'").replace('â€˜', "'")
                        text = unicodedata.normalize('NFKD', text)
                        return text.encode('ascii', 'ignore').decode()

                    valid_cat_df['Rkategori_norm'] = valid_cat_df['Rkategori'].apply(_normalize)
                    valid_cat_df['Tkategori_norm'] = valid_cat_df['Tkategori'].apply(_normalize)

                    true_cat = valid_cat_df['Rkategori_norm']
                    pred_cat = valid_cat_df['Tkategori_norm']
                    
                    cat_correct = (true_cat == pred_cat).sum()
                    cat_total = len(valid_cat_df)
                    cat_accuracy = cat_correct / cat_total
                    
                    print(f"   Total samples: {cat_total}")
                    print(f"   Correct predictions: {cat_correct}")
                    print(f"   Category Accuracy: {cat_accuracy:.2%}")
                    
                    try:
                        from sklearn.metrics import classification_report
                        print("\nðŸ“ˆ Category Classification Report:")
                        print(classification_report(true_cat, pred_cat, zero_division=0))
                    except ImportError:
                        pass
                
            else:
                print("   âš ï¸ No valid RDuygu labels found after normalization")
        else:
            print("   âš ï¸ No valid samples found (both RDuygu and Tduygu must be non-empty)")
        
        print(f"\nâœ… Analysis complete! Results saved to: {output_file}")
        
    except FileNotFoundError:
        print(f"âŒ File not found: {input_file}")
        print("   Please make sure the file exists in the current directory.")
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Komut satÄ±rÄ±ndan dosya adÄ± ve Ã¶rnek sayÄ±sÄ± alÄ±nabilir
    input_file = sys.argv[1] if len(sys.argv) > 1 else 'TestVeri_Duygulu.xlsx'
    output_file = sys.argv[2] if len(sys.argv) > 2 else 'TestVeri_Duygulu_Analyzed.xlsx'
    samples_per_category = int(sys.argv[3]) if len(sys.argv) > 3 else 10
    
    analyze_test_data(input_file, output_file, samples_per_category)
